{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Introduction to Python for Humanists\n",
    "\n",
    "### Motivating Project\n",
    "\n",
    "### Programming in Python\n",
    "<ul>\n",
    "    <li>Basic Data Types & Operations</li>\n",
    "    <ul>\n",
    "        <li>Arithmetic</li>\n",
    "        <li>Variable Assignment</li>\n",
    "        <li>Strings</li>\n",
    "        <li>Lists</li>\n",
    "    </ul>\n",
    "    <li>A few tricks up your sleeve</li>\n",
    "    <ul>\n",
    "        <li>String Methods</li>\n",
    "        <li>List Comprehension</li>\n",
    "    </ul>\n",
    "</ul>\n",
    "\n",
    "### Introduction to NLTK\n",
    "<ul><li>Modules & Corpora</li>\n",
    "<li>Concordance Building</li>\n",
    "<li>Word Frequencies</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Building Intuition\n",
    "\n",
    "Inside the folder that contains this script, there is a plaintext file with notes taken during Professor Emily Thornbury's talk \"Stop Having Ideas and Start Counting.\" The title contains two present progressive (<i>-ing</i>) verbs, which might suggest we look for others in the body of the text, if we were to do something like a literary analysis.\n",
    "\n",
    "Part of the reason why people use Python to do work on human-language texts (<i>natural language processing</i>) is because it makes tasks like this relatively simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (don't worry about understanding everything here)\n",
    "!pip install nltk\n",
    "!pip install matplotlib\n",
    "for line in open('lecture notes 09-22-15.txt'):\n",
    "    for word in line.split():\n",
    "        if word.endswith('ing'):\n",
    "            print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Basic Data Types & Operations\n",
    "## Arithmetic\n",
    "\n",
    "Before doing any more NLP, let's start with the basics. Any time you work with computers, it is essential to remember that they are simply counting machines. Place-holders with zeros and ones represent numbers that get added and subtracted from one another. This is true even for language -- but let's not get ahead of ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addition (btw, any line that starts with a hashtag \"#\" like this is a comment, and is not code)\n",
    "\n",
    "2+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have Python report the results from three operations at the same time\n",
    "\n",
    "print(2-5)\n",
    "print(2*5)\n",
    "print(2/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we have all of our operations in the last line of the cell, Jupyter will print them together\n",
    "\n",
    "2-5, 2*5, 2/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And let's compare values. \n",
    "# \">\" (bigger than) and \"<\" (smaller than) can be used to check whether one number is bigger than another\n",
    "\n",
    "2>5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable assignment\n",
    "\n",
    "Assigning variables is something that we do all the time in programming. These aren't quite like the variables from high school algebra, where <i>x</i> represents an unknown to solve for. Instead these are like notes to ourselves that we want to save some value(s) for later use.\n",
    "\n",
    "Note that the equals sign is directional, like an arrow, telling the computer to give a certain value to a certain label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'a' is being given the value 2; 'b' is given 5\n",
    "\n",
    "a = 2\n",
    "b = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's perform an operation on the variables\n",
    "\n",
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables can have many different kinds of names\n",
    "\n",
    "this_number = 2\n",
    "b/this_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strings\n",
    "\n",
    "In Python, human language text gets represented as a <i>string</i>. These contain sequential sets of characters and they are offset by quotation marks, either double (\") or single (').\n",
    "\n",
    "We will explore different kinds of operations in Python that are specific to human language objects, but it is useful to start by trying to see them as the computer does, as numerical representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The iconic string\n",
    "\n",
    "print(\"Hello, World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign these strings to variables\n",
    "\n",
    "a = \"Hello\"\n",
    "b = 'World'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out arithmetic operations.\n",
    "# When we add strings we call it 'concatenation'\n",
    "\n",
    "print(a+b)\n",
    "print(a*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unlike a number that consists of a single value, a string is an ordered\n",
    "# sequence of characters. We can find out the length of that sequence.\n",
    "\n",
    "len(\"Hello, World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXERCISE. How long is the string below?\n",
    "\n",
    "this_string = \"As anyone who has watched Time Team will know, the context is all in archaeology.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lists\n",
    "\n",
    "The <i>numbers</i> and <i>strings</i> we have just looked at are the two basic data types that we will focus our attention on in this workshop. (In a next module, we will look at a third data type, <i>boolean</i>, which consists of just True/False values.) When we are working with just a few numbers or strings, it is easy to keep track of them, but as we collect more we will want a system to organise them.\n",
    "\n",
    "One such organisational system is a <i>list</i>. This contains values (regardless of type) in order, and we can perform operations on it very similarly to the way we did with numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list in which each element is a string\n",
    "\n",
    "['Pyramids', 'are', 'interesting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's assign a couple lists to variables\n",
    "\n",
    "list1 = ['Pyramids', 'are', 'interesting']\n",
    "list2 = ['Stonehenge', 'is', 'mysterious']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q. Predict what will happen when we perform the following operations\n",
    "\n",
    "print(list1+list2)\n",
    "print(list1*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Like a string, we can find out the length of a list\n",
    "\n",
    "len(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes we just want a single value from the list at a time\n",
    "# Each item in a list has an index (a number), counting from zero upwards. So the first item has index '0'!\n",
    "\n",
    "print(list1[0]) # first item\n",
    "print(list1[1]) # second item\n",
    "print(list1[2]) # third item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or maybe we want the first few\n",
    "\n",
    "print(list1[0:2]) # [0:2] means item with index 0 to item with index 2\n",
    "print(list1[:2]) # [:2] means from the start to index 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXERCISE. Concatenate 'list1' and 'list2' into a single list.\n",
    "##           Retrieve the third element from the combined list.\n",
    "##           Retrieve the fourth through sixth elements from the combined list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String Methods\n",
    "\n",
    "The creators of Python recognise that human language has many important yet idiosyncratic features, so they have tried to make it easy for us to identify and manipulate them. For example, in the demonstration at the very beginning of the workshop, we referred to the idea of the suffix: the final letters of a word tell us something about its grammatical role and potentially semantics.\n",
    "\n",
    "We can analyse or manipulate certain features of a string using its <i>methods</i>. These are basically internal functions that every string automatically gets assigned. Note that even though the method may transform the string at hand, they don't change it permanently!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's assign a variable to perform methods upon\n",
    "\n",
    "greeting = \"Hello, World!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We saw the 'endswith' method at the very beginning\n",
    "# Note the type of output that gets printed\n",
    "\n",
    "greeting.startswith('H'), greeting.endswith('d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can check whether the string is a letter or a number\n",
    "\n",
    "# When there are multiple characters, it checks whether *all*\n",
    "# of the characters belong to that category\n",
    "\n",
    "greeting.isalpha(), greeting.isdigit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly, we can check whether the string is lower or upper case, or is capitalised like a title\n",
    "\n",
    "greeting.islower(), greeting.isupper(), greeting.istitle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes we want not just to check, but to change the string\n",
    "\n",
    "greeting.lower(), greeting.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The case of the string hasn't changed!\n",
    "\n",
    "greeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But if we want to permanently make it lower case we re-assign it\n",
    "\n",
    "greeting = greeting.lower()\n",
    "\n",
    "greeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oh hey. And strings are kind of like lists, so we can slice them similarly\n",
    "\n",
    "greeting[:3] # get first 3 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strings may be like lists of characters, but as humans we treat them as\n",
    "# lists of words. We can perform that conversion for the computer.\n",
    "\n",
    "greeting.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXERCISE. Return the second through eighth characters in 'greeting'\n",
    "\n",
    "## EXERCISE. Split the string below into a list of words and assign this to a new variable\n",
    "\n",
    "## Challenge: Return the characters from the first half of 'greeting'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_string = \"And they always find in archaeology, a series of small walls.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to NLTK\n",
    "\n",
    "The Natural Language Toolkit (NLTK) is a suite of Natural Language Processing tools that are designed to be easy to use while achieving near state-of-the-art performance. These will allow us to do things like tag parts of speech to the words in our strings, identify synonyms and other semantic relationships, and perform useful statistics on our collections of words.\n",
    "\n",
    "We will look at NLTK's most essential functions in the next modules in order to start building our tools from the ground up. Today, however, we will focus our attention on a few popular, higher order functions that NLTK makes available, including counting word frequencies and producing concordances (a list of sentences in which a word occurs, see below).\n",
    "\n",
    "To be more precise, NLTK is a <i>package</i>, which expands the functionality of Python by making new functions, methods, and data available. In order to access a package, we must first download it to our computers (which you have already done if you installed Anaconda) and then activate it by <i>importing</i> the package into our script. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essential NLTK functions\n",
    "\n",
    "<table align='left'>\n",
    "    <tr>\n",
    "        <td>Processing raw text</td>\n",
    "        <td>nltk.tokenize, nltk.stem</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Part of Speech and Grammar</td>\n",
    "        <td>nltk.tag, nltk.chunk, nltk.parse</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Semantic Meaning</td>\n",
    "        <td>nltk.stem.wordnet</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Statistical measures</td>\n",
    "        <td>nltk.metrics, nltk.probability, nltk.collocations</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example NLTK corpora of humanistic interest\n",
    "\n",
    "<table align='left'>\n",
    "    <tr>\n",
    "        <td>Project Gutenberg: Lit</td>\n",
    "        <td>nltk.corpus.gutenberg\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Webpages, chat</td>\n",
    "        <td>nltk.corpus.webtext\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Twitter</td>\n",
    "        <td>nltk.corpus.twitter\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Brown Corpus</td>\n",
    "        <td>nltk.corpus.brown\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Reuters: News</td>\n",
    "        <td>nltk.corpus.reuters\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Inaugural Addr. (US)</td>\n",
    "        <td>nltk.corpus.inaugural</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Mody Dick from a plaintext file in the current folder\n",
    "\n",
    "moby_string = open('Melville - Moby Dick.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the string!\n",
    "# (Notice the '\\n' symbols? Those are line endings.)\n",
    "# (See if you can spot any noise in the text below!)\n",
    "\n",
    "moby_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the string into a list of words\n",
    "\n",
    "moby_list = moby_string.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the beginning of the list\n",
    "\n",
    "moby_list[:10] # first 10 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NLTK!\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use NLTK's 'Text' function to give 'moby_list' some new methods\n",
    "\n",
    "moby_text = nltk.Text(moby_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moby_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Has the familiar list slicing method\n",
    "\n",
    "moby_text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Has the same length as our old 'moby_list'\n",
    "\n",
    "len(moby_list), len(moby_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But it's now very easy to produce a concordance\n",
    "\n",
    "moby_text.concordance('whale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also find words that appear in similar contexts \n",
    "# (Remember word embeddings? This is another use for them)\n",
    "\n",
    "moby_text.similar('whale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And we can find out what those shared contexts are\n",
    "\n",
    "moby_text.common_contexts([\"whale\", 'ship'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get a report of word frequencies in the text\n",
    "# (A frequency is just a count! This is a list of each word, and how often it occurs)\n",
    "\n",
    "nltk.FreqDist(moby_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign these to a variable\n",
    "\n",
    "fdist = nltk.FreqDist(moby_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ten most frequent words in Moby Dick\n",
    "\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency of 'whale' in Moby Dick\n",
    "\n",
    "fdist['whale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Often we want to normalise the frequency as a proportion of all words in the text\n",
    "# (Remember dividing word count by the length of the document, instead of taking the raw word count?)\n",
    "\n",
    "fdist.freq('whale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's get a simple list of unique words in Moby Dick\n",
    "\n",
    "fdist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXERCISE. A common measure of lexical diversity for a given text is its Type-Token Ratio:\n",
    "##           the number of unique words (types) divided by the total number of words (tokens)\n",
    "##           The more unique words, the higher the vocabulary for a text, the higher the diversity.\n",
    "##           Calculate the Type-Token Ratio for Moby Dick."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's graph the top 50 words in Moby Dick by descending frequency\n",
    "\n",
    "fdist.plot(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternately, we can plot the words cumulatively so we can\n",
    "# see how much of the text is accounted\n",
    "\n",
    "fdist.plot(50, cumulative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE. Transform the excerpt from Eddie Izzard's sketch below into a list of words, then plot their frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (slashes at the end of a line allow you to continue a variable on the next line without Python errors)\n",
    "eddie_izzard_sketch = \"And we have archaeology on TV. I quite like it, it's a sort of detective thing \\\n",
    "    but it's really tricky, you know, it's there. But it's kind of slow on telly. \\\n",
    "    It has this problem of, We've been here three weeks on live TV and we've dug up a millimetre of topsoil so far. \\\n",
    "    We've found this and carbon dated it to last Tuesday, so we're very excited. \\\n",
    "    It's too slow. Our attention spans are short. We need stuff! Quick, change the channel! \\\n",
    "    We want, not slow archaeology, we want speed archaeology! \\\n",
    "    You've got 10 minutes to find a city. All right! Let's go! Get the diggers in! Brrr! Brrr!\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
