{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<h1 align='center'>It Starts with a Humanistic Research Question...</h1>\n",
    "<img src='Long, So 263, Fig 8.png' width=\"66%\" height=\"66%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get texts of interest that belong to identifiably different categories\n",
    "\n",
    "unladen_swallow = 'high air-speed velocity'\n",
    "swallow_grasping_coconut = 'low air-speed velocity'\n",
    "\n",
    "# Transform them into the format NLTK expects\n",
    "\n",
    "unladen_features_tagged = ({'high':True, 'low': False, 'air-speed': True, 'velocity': True},\\\n",
    "                           'unladen')\n",
    "coconut_features_tagged = ({'high': False, 'low':True, 'air-speed': True, 'velocity': True},\\\n",
    "                           'coconut')\n",
    "\n",
    "# Train a classifier to learn distinguishing features\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train([unladen_features_tagged, coconut_features_tagged])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# It's a simple question of weight ratios!\n",
    "# A five ounce bird could not carry a one pound coconut. \n",
    "\n",
    "unknown_swallow = \"high velocity\"\n",
    "unknown_features = {'high':True, 'low': False, 'air-speed': False, 'velocity':True}\n",
    "\n",
    "classifier.classify(unknown_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read Moby Dick\n",
    "with open('Melville - Moby Dick.txt','r') as file_in:\n",
    "    moby_string = file_in.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inspect the text\n",
    "moby_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make the text lower case\n",
    "moby_lower = moby_string.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tokenize Moby Dick\n",
    "from nltk import word_tokenize\n",
    "moby_tokens = word_tokenize(moby_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check out the tokens\n",
    "moby_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Just how long is Moby Dick anyway?\n",
    "len(moby_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a dictionary that counts token frequencies\n",
    "from collections import Counter\n",
    "moby_dict = Counter(moby_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dictionaries pair keys with values\n",
    "moby_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Report the ten most common tokens in the novel\n",
    "moby_dict.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the frequency of a specific word\n",
    "moby_dict['whale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list comprehension, including an 'if' statement\n",
    "just_whales = [token for token in moby_tokens if token=='whale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hast seen the White Whale?\n",
    "just_whales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operating System Interface!\n",
    "\n",
    "Even though it sounds banal, this is the moment your computer ceases to be an appliance and transforms into a tool. The <i>os</i> package allows Python to speak with the rest of your computer's systems and file storage. You now have access to any file on your computer and can manipulate them using the code you have learned so far. With great power comes great responsibility!\n",
    "\n",
    "For now, we will look at just one function from <i>os</i> that gives us access to our corpora when they are separated into individual, plaintext files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Report the files in the current folder\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Follow one of the reported folders\n",
    "os.listdir('movie_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And follow deeper\n",
    "os.listdir('movie_reviews/negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign that list to a variable\n",
    "negative_files = os.listdir('movie_reviews/negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inspect first element in a list\n",
    "negative_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## EX. How many reviews are there in the 'positive' folder?\n",
    "##     How many in the 'negative' one?\n",
    "\n",
    "## EX. Get a list of files in each of the following paths.\n",
    "##     Assign these to separate variables.\n",
    "\n",
    "review_path = 'poems/random/'\n",
    "random_path = 'poems/reviewed/'\n",
    "\n",
    "## CHALLENGE: Find a list of files and folders on your desktop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpora\n",
    "\n",
    "The main corpus we will use for our exercises are a set of positive and negative movie reviews made available through NLTK. Each review is contained in its own <i>.txt</i> file, and these reside in their respective folders, \"positive\" and \"negative\".\n",
    "\n",
    "Although positive and negative reviews capture rough ideas of taste and distinction, Ted Underwood and Jordan Sellers have done a literary historical study on  nineteenth- and early-twentieth volumes of poetry that were reviewed in prestigious magazines versus not at all. The idea being that even a negative review indicates valuable, critical engagement.\n",
    "\n",
    "Underwood and Sellers have made their corpus publicly available, so we will apply the techniques we learn to these as we proceed. Note that due to issues of copyright, volumes' word order has not been retained, although their total word counts have been. Fortunately, our methods do not require word-order information.\n",
    "\n",
    "Their literary corpus has been divided into three folders: \"reviewed\", \"random\", \"canonic\". (The last of these are canonic poets but who did not have the opportunity to be reviewed, such as Emily Dickinson.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Open the first file from negative_files\n",
    "open('movie_reviews/negative/cv000_29416.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# When opening others, filenames change but the path doesn't!\n",
    "path = \"movie_reviews/negative/\"\n",
    "open(path+'cv000_29416.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read all files and assign to a variable\n",
    "negative_reviews = [open(path+name,'r').read() for name in negative_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE: If you are using OSX, your operating system may sometimes\n",
    "# include hidden files in your folders that confuse Python.\n",
    "\n",
    "# If you get an error while running this line, try including an 'if' condition\n",
    "# in your list comprehension to prevent Python from tripping over these.\n",
    "\n",
    "# For example:\n",
    "negative_reviews = [open(path+name,'r').read() for name in negative_files if name[-4:]=='.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Repeat process for positive reviews\n",
    "path = 'movie_reviews/positive/'\n",
    "positive_files = os.listdir(path)\n",
    "positive_reviews = [open(path+name,'r').read() for name in positive_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inspect first element in list\n",
    "positive_reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EX. How long is the list of positive movie reviews? Negative reviews?\n",
    "##     Do these match the number of files you had observed in the folders?\n",
    "\n",
    "## EX. Retrieve the files from the 'reviewed' and 'random' folders of poetry.\n",
    "##     Create a separate list for each category, in which each element is a\n",
    "##     string with a file's text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Set\n",
    "\n",
    "The feature set we will use is a simple one: Does the volume of poetry contain a given word? True or False. The idea is that one category of movie review (or poetry volume) may be distinguishable from the other based on their vocabularies. For example, words like \"terrible\" or \"mediocre\" are presumably less likely to appear in positive reviews.\n",
    "\n",
    "It is often useful to look at high-frequency terms in a corpus. Intuitively, not all words in the corpus will convey the same amount of information about whether a review is positive or negative. At the extreme, if a word appears in just a single review out of thousands, it doesn't tell us much either way about whether that word is associated with a category. By removing infrequent terms from our model, we can also save computational time.\n",
    "\n",
    "In this case, we will include just the 1000 most frequent words for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tokenize our sets of reviews; tokens remain grouped by review\n",
    "\n",
    "negative_tokenized = [word_tokenize(review.lower()) for review in negative_reviews]\n",
    "positive_tokenized = [word_tokenize(review.lower()) for review in positive_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inspect\n",
    "positive_tokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ungroup words from their reviews; returns a flat list of words\n",
    "\n",
    "negative_words = [token for review in negative_tokenized for token in review]\n",
    "positive_words = [token for review in positive_tokenized for token in review]\n",
    "\n",
    "# Combine lists\n",
    "all_words = negative_words + positive_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a dictionary where keys are unique words\n",
    "# and entries are the number of times they appear\n",
    "\n",
    "from collections import Counter\n",
    "all_words_counted = Counter(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inspect\n",
    "all_words_counted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get a list of the most common words and their frequencies\n",
    "all_words_counted.most_common(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Assign the list to a variable\n",
    "common_words = [word for word,count in all_words_counted.most_common(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inspect\n",
    "common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EX. How many words are there total in the movie review corpus?\n",
    "\n",
    "## CHALLENGE: How many unique words are there in the movie review corpus?\n",
    "##            What is the average number of times each word appears?\n",
    "\n",
    "## EX. Tokenize each poetry volume. Create a list for each category ('reviewed'/'random').\n",
    "\n",
    "## EX. Get a list of the 500 most frequent terms in the poetry corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurize Texts\n",
    "\n",
    "For humans, reading a string of text is a relatively easy task, but for the computer to learn about language, text has to be represented in very particular ways. We refer to this as <i>featurization</i>: the transformation of a text into a quantitative feature set.\n",
    "\n",
    "In order for the NLTK classifier to work, we have to represent each text as a set of True/False values: Is a given word from our high-frequency vocabulary present in this review? More specifically, these values will be contained in a dictionary, where each key is a vocabulary word and its value is whether or not it is present.\n",
    "\n",
    "Once we have processed each text according to this rubric, we will then attach a label for the text's category ('positive'/'negative). The classifier will use this to identify which features are associated with each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dummy review tokens\n",
    "test_review = [\"i\",\"loved\",\"this\",\"movie\",\"!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Is the word 'this' in the test_review?\n",
    "'this' in test_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Is the word 'duck' in the test_review?\n",
    "'duck' in test_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Iterate through high-frequency vocabulary to test words\n",
    "for word in common_words:\n",
    "    print(word, word in test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Record these values in a dictionary comprehension!\n",
    "{word:word in test_review for word in common_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Turn our reviews into dictionaries that indicate whether a word is present\n",
    "negative_featurized = [{word:word in review for word in common_words} \\\n",
    "                       for review in negative_tokenized]\n",
    "\n",
    "positive_featurized = [{word:word in review for word in common_words} \\\n",
    "                       for review in positive_tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inspect\n",
    "negative_featurized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Attach a label to each review\n",
    "negative_tagged = [(review,'negative') for review in negative_featurized]\n",
    "positive_tagged = [(review,'positive') for review in positive_featurized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inspect\n",
    "negative_tagged[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Combine these lists of featurized, tagged reviews\n",
    "all_tagged = negative_tagged + positive_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EX. Featurize and tag the volumes of 'reviewed' and 'random' poetry.\n",
    "##     Return a list containing all poems in the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "We have selected an algorithm that specifically relies on <a href=\"https://en.wikipedia.org/wiki/Bayes%27_theorem\">Bayes' Theorem</a> to model relationships between textual features and categories in our corpus of movie reviews. (See link for more information about the method and its assumptions.)\n",
    "\n",
    "Two ways that we learn about the model are its feature weights and predictions on new texts. The algorithm can explicity report to us which direction each word leans category-wise and how strongly. Based on those weights, it makes further predictions about the valences previously unseen movie reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train the classifier and assign it to a variable\n",
    "\n",
    "from nltk import NaiveBayesClassifier\n",
    "classifier = NaiveBayesClassifier.train(all_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Report feature information\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import, featurize test set of reviews\n",
    "\n",
    "positive_test_string = open('movie_reviews/test/New York Times - Zootopia (positive review).txt').read()\n",
    "positive_test_tokens = word_tokenize(positive_test_string)\n",
    "positive_test_features = {word:word in positive_test_tokens for word in common_words}\n",
    "\n",
    "negative_test_string = open('movie_reviews/test/Cinemixtape - Zootopia (negative review).txt').read()\n",
    "negative_test_tokens = word_tokenize(negative_test_string)\n",
    "negative_test_features = {word:word in negative_test_tokens for word in common_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict whether new reviews are positive or negative\n",
    "classifier.classify_many([positive_test_features,negative_test_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Just how confident is our classifier of its predictions?\n",
    "classifier.prob_classify(positive_test_features).prob('positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier.prob_classify(negative_test_features).prob('negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EX. Train a classifier on the featurized, tagged poetry corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra: Validation\n",
    "\n",
    "Just how good is our classifier? We can evaluate it by randomly selecting reviews from each category and setting them aside before training. We then see how well the classifier predicts their (known) categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Randomize our list of movie reviews (in place)\n",
    "\n",
    "import numpy\n",
    "numpy.random.shuffle(all_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We'll train our classifier on the first 90% of reviews\n",
    "# and validate using the last 10%\n",
    "\n",
    "training_set = all_tagged[:-200]\n",
    "validation_set = all_tagged[-200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train, validate\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "nltk.classify.accuracy(classifier, validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CHALLENGE: Validate the model you trained on the poetry corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Literary Distinction\n",
    "\n",
    "In their study of critical taste, Underwood and Sellers find not only that literary standards change very slowly, but that contemporary metrics of 'canonicity' resemble those of the nineteenth century.\n",
    "\n",
    "In order to test this idea, the authors trained a classifier on nineteenth- and early twentieth-century volumes of poetry that received reviews in a prestigious magazine versus those that didn't. The authors then used the classifier to predict a category for volumes of poetry that went unreviewed, in several cases because they were unpublished, but are now included in Norton anthologies.\n",
    "\n",
    "How closely does critical evaluation today match that of a century ago?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EX. If you have not already, train a classifier on the featurized, tagged poetry corpus.\n",
    "\n",
    "## EX. Import and process the 'canonic' (albeit unreviewed) volumes of poetry.\n",
    "##     Use the poetry classifier to predict whether they might have been reviewed.\n",
    "\n",
    "canonic_path = 'poems/canonic/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
